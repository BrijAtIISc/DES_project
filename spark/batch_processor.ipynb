{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, functions as F, types as T, Window as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/05 13:10:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Set up the Spark configuration and context\n",
    "conf = SparkConf().setAppName(\"MyApp\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Set up the Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BatchProcessor\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Xss4m\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Xss4m\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+----------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             authors|        date_google|       date_metadata|     date_published|        date_target|         description|         explanation|          groq_usage|            metadata|rating_democrats|rating_republicans|          source_url|             summary|                text|               title|                 url|\n",
      "+--------------------+-------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+----------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                  []|2024-08-22T10:28:41| 2024-08-22T10:28:41|               NULL|2024-02-10T00:00:00|The News Literacy...|This text is neut...|CompletionUsage(c...|{article -> {\"mod...|             1.0|               0.0| https://newslit.org| The Misinformati...|Election 2024: Be...|Election 2024: Be...|https://newslit.o...|\n",
      "|                  []|               NULL|                NULL|               NULL|2024-02-10T00:00:00|The US presidenti...|This text is high...|CompletionUsage(c...|{description -> T...|             4.0|              -4.0| https://www.bbc.com| Trump says he wo...|Trump says he wou...|Trump says he wou...|https://www.bbc.c...|\n",
      "|      [Simone Pathe]|2024-02-10T10:30:29|2024-02-10T10:30:...|2024-02-10T00:00:00|2024-02-10T00:00:00|It wonâ€™t suck up ...|The text is sligh...|CompletionUsage(c...|{article -> {\"mod...|             2.0|              -1.0| https://www.cnn.com| The race for the...|Why the race for ...|Why the race for ...|https://www.cnn.c...|\n",
      "|    [Edward Helmore]|2024-02-12T14:29:40| 2024-02-12T14:29:40|2024-02-11T00:00:00|2024-02-10T00:00:00|The Joe Biden Whi...|This text is high...|CompletionUsage(c...|{al -> {\"ios\":{\"a...|             2.0|              -4.0|https://www.thegu...| Trump says he wo...|Trump says he wou...|Trump says he wou...|https://www.thegu...|\n",
      "|[Lawless Is An As...|2024-02-11T05:04:32| 2024-02-11T05:04:32|2024-02-11T05:04:32|2024-02-10T00:00:00|With a divided el...|This text is unfa...|CompletionUsage(c...|{article -> {\"aut...|             1.0|              -3.0|  https://apnews.com| Many worry that ...|Allies fear the U...|Allies fear the U...|https://apnews.co...|\n",
      "+--------------------+-------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+----------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"authors\", T.ArrayType(T.StringType()), True),\n",
    "    T.StructField(\"date_google\", T.StringType(), True),\n",
    "    T.StructField(\"date_metadata\", T.StringType(), True),\n",
    "    T.StructField(\"date_published\", T.StringType(), True),\n",
    "    T.StructField(\"date_target\", T.StringType(), True),\n",
    "    T.StructField(\"description\", T.StringType(), True),\n",
    "    T.StructField(\"explanation\", T.StringType(), True),\n",
    "    T.StructField(\"groq_usage\", T.StringType(), True),\n",
    "    T.StructField(\"metadata\", T.MapType(T.StringType(), T.StringType()), True),\n",
    "    T.StructField(\"rating_democrats\", T.FloatType(), True),\n",
    "    T.StructField(\"rating_republicans\", T.FloatType(), True),\n",
    "    T.StructField(\"source_url\", T.StringType(), True),\n",
    "    T.StructField(\"summary\", T.StringType(), True),\n",
    "    T.StructField(\"text\", T.StringType(), True),\n",
    "    T.StructField(\"title\", T.StringType(), True),\n",
    "    T.StructField(\"url\", T.StringType(), True)\n",
    "])\n",
    "news_df = spark.read.option(\"multiline\", \"true\").json(\"../news_ratings/data/\", schema=schema)\n",
    "news_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-----------------+------------------+-----------------+------------------+------------------+-----------+\n",
      "|Ticker|               Date|             Open|              High|              Low|             Close|         Adj Close|     Volume|\n",
      "+------+-------------------+-----------------+------------------+-----------------+------------------+------------------+-----------+\n",
      "|   XLP|2023-11-16 20:00:00| 69.8499984741211| 69.86000061035156|69.55999755859375| 69.66500091552734| 69.66500091552734|  4150005.0|\n",
      "|   IJR|2023-11-16 20:00:00|96.30000305175781| 96.58000183105469|95.19999694824219| 95.44999694824219| 95.44999694824219|   997585.0|\n",
      "|   SPY|2023-11-16 20:00:00|449.2200012207031|450.55999755859375|449.1300048828125|449.95001220703125|449.95001220703125|1.0474895E7|\n",
      "|   XLU|2023-11-16 20:00:00|62.29999923706055|  62.6150016784668|62.06999969482422|62.470001220703125|62.470001220703125|  3710716.0|\n",
      "|   XLB|2023-11-16 20:00:00|79.86000061035156| 80.20999908447266| 79.6500015258789| 79.87999725341797| 79.87999725341797|   893243.0|\n",
      "+------+-------------------+-----------------+------------------+-----------------+------------------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "market_df = spark.read.csv(\"../stocks_data/ticker_data.csv\", header=True, inferSchema=True)\n",
    "market_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticker: string (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "market_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+----------------+------------------+--------------------+--------------------+--------------------+\n",
      "|       published_at|date_target|rating_democrats|rating_republicans|               title|             summary|                 url|\n",
      "+-------------------+-----------+----------------+------------------+--------------------+--------------------+--------------------+\n",
      "|2024-02-12 22:28:29| 2024-02-12|             0.0|               0.0|Primary Election ...| San Diego County...|https://www.kpbs....|\n",
      "|2024-02-16 16:57:52| 2024-02-16|             1.0|               0.0|President Biden R...| President Biden ...|https://www.c-spa...|\n",
      "|2024-02-21 20:31:14| 2024-02-20|             1.0|               1.0|Which is the bett...| In the past, spe...|https://abcnews.g...|\n",
      "|2024-02-21 11:45:34| 2024-02-21|             0.0|               0.0|AP Decision Notes...| Donald Trump and...|https://apnews.co...|\n",
      "|2024-02-23 05:00:04| 2024-02-21|             0.0|               0.0|Will â€˜micro-influ...| Discover the FTâ€™...|https://www.ft.co...|\n",
      "+-------------------+-----------+----------------+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_df = news_df.withColumn(\"published_at\", F.coalesce(\"date_google\", \"date_metadata\", \"date_published\")) \\\n",
    "    .withColumn(\"published_at\", F.to_timestamp(\"published_at\")) \\\n",
    "    .withColumn(\"date_target\", F.to_date(\"date_target\"))\n",
    "news_df = news_df.select('published_at', 'date_target', 'rating_democrats', 'rating_republicans', 'title', 'summary', 'url')\n",
    "news_df = news_df.na.drop(subset=[\"published_at\"])\n",
    "news_df.sample(fraction=0.01).show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windows = [\n",
    "  1,      # 1 hour\n",
    "#   5,      # 5 hours\n",
    "  10,     # 10 hours\n",
    "  24,     # 1 day\n",
    "#   7*24,   # 1 week\n",
    "#   14*24,  # 2 weeks\n",
    "#   28*24,  # 4 weeks\n",
    "]\n",
    "# --------------------\n",
    "statistics = [\n",
    "  \"count\",\n",
    "  \"mean\",\n",
    "  \"std\",\n",
    "  \"min\",\n",
    "  \"max\",\n",
    "  \"median\",\n",
    "  \"spread\",\n",
    "]\n",
    "# --------------------\n",
    "ticker_cols = [\n",
    "  \"Open\",\n",
    "  \"High\",\n",
    "  \"Low\",\n",
    "  \"Close\",\n",
    "  \"Adj Close\",\n",
    "  \"Volume\"\n",
    "]\n",
    "# --------------------\n",
    "news_cols = [\n",
    "  \"rating_republicans\",\n",
    "  \"rating_democrats\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function for rolling window calculations\n",
    "def calculate_rolling_stats(df, cols, datetime_col, partition_col=None):\n",
    "    \"\"\"\n",
    "    Computes rolling statistics for a given column over various time windows.\n",
    "    \"\"\"\n",
    "    result_df = df\n",
    "    for window_hours in time_windows:\n",
    "        # Define the window range in milliseconds\n",
    "        window_range = window_hours * 3600 * 1000\n",
    "        # Define a rolling window spec\n",
    "        window_spec = (\n",
    "            W\n",
    "            .partitionBy(partition_col if partition_col else [])\n",
    "            .orderBy(F.col(datetime_col).cast(\"timestamp\").cast(\"long\") * 1000)\n",
    "            .rangeBetween(-window_range, 0)\n",
    "        )\n",
    "        for col in cols:\n",
    "            for stat in statistics:\n",
    "                col_name = f\"rolling_{window_hours}h_{col}_{stat}\"\n",
    "                if   stat == \"count\":   result_df = result_df.withColumn(col_name, F.count(col).over(window_spec))\n",
    "                elif stat == \"mean\":    result_df = result_df.withColumn(col_name, F.mean(col).over(window_spec))\n",
    "                elif stat == \"std\":     result_df = result_df.withColumn(col_name, F.stddev(col).over(window_spec))\n",
    "                elif stat == \"min\":     result_df = result_df.withColumn(col_name, F.min(col).over(window_spec))\n",
    "                elif stat == \"max\":     result_df = result_df.withColumn(col_name, F.max(col).over(window_spec))\n",
    "                elif stat == \"median\":  result_df = result_df.withColumn(col_name, F.approx_percentile(col, 0.5, 10).over(window_spec))\n",
    "                elif stat == \"spread\":  result_df = result_df.withColumn(col_name, F.max(col).over(window_spec) - F.min(col).over(window_spec))\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "market_rollstats_df = calculate_rolling_stats(market_df, ticker_cols, \"Date\", \"Ticker\")\n",
    "news_rollstats_df = calculate_rolling_stats(news_df, news_cols, \"published_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# sc.stop()       # Stop the Spark contex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

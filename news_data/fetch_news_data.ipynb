{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5G7hDBy6YX4D"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from newspaper import Article, Config\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tz = lambda dt:   dt.astimezone(timezone.utc).replace(tzinfo=None) if dt.tzinfo else dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "p32crnSLYX4F"
   },
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    config = Config()\n",
    "    config.request_timeout = 10\n",
    "    config.follow_meta_refresh = True\n",
    "    config.memoize_articles = False\n",
    "    config.fetch_images = False\n",
    "    config.browser_user_agent = random.choice([\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/111.0.1661.62',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/110.0',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0'\n",
    "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',\n",
    "    ])\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1MalD08NYX4G"
   },
   "outputs": [],
   "source": [
    "class CustomArticle(Article):\n",
    "    def build(self):\n",
    "        super().build()\n",
    "        soup = BeautifulSoup(self.html, 'html.parser')\n",
    "\n",
    "        if not self.authors:\n",
    "            candidates = map(lambda x: x.get_text().strip(), soup.select('a[href*=author]'))\n",
    "            self.authors.extend(candidates)\n",
    "\n",
    "        if not self.text:\n",
    "            paragraphs = soup.find_all('p')\n",
    "            lists = soup.find_all('ul')\n",
    "            divs = soup.find_all('div')\n",
    "\n",
    "            para_text = \"\\n\".join([p.get_text().strip() for p in paragraphs])\n",
    "            list_text = \"\\n\".join([ul.get_text().strip() for ul in lists])\n",
    "            divs_text = \"\\n\".join([d.get_text().strip() for d in divs])\n",
    "\n",
    "            self.text = para_text + \"\\n\" + list_text + \"\\n\" + divs_text\n",
    "            self.text = self.text.strip()\n",
    "\n",
    "\n",
    "    @property\n",
    "    def datetime(self):\n",
    "        date_pattern = r'\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?(?:Z|[+-]\\d{2}:\\d{2})?'\n",
    "        json_str = json.dumps(self.meta_data)\n",
    "        if matches := re.findall(date_pattern, json_str):\n",
    "            dt = datetime.fromisoformat(sorted(matches)[len(matches) // 2])\n",
    "            return no_tz(dt).isoformat()\n",
    "\n",
    "        date_patterns = [\n",
    "            (\"%B %d, %Y, %H:%M\", r\"\\b\\w+ \\d{1,2}, \\d{4}, \\d{2}:\\d{2}\"),\n",
    "            (\"%b %d, %Y, %H:%M\", r\"\\b\\w{3} \\d{1,2}, \\d{4}, \\d{2}:\\d{2}\"),\n",
    "            (\"%b %d, %Y %H:%M\", r\"\\b\\w{3} \\d{1,2}, \\d{4} \\d{2}:\\d{2}\"),\n",
    "            (\"%d %b %I:%M %p\", r\"\\b\\d{1,2} \\w{3} \\d{1,2}:\\d{2} (?:am|pm)\"),\n",
    "            (\"%H:%M (IST) %d %b %Y\", r\"\\d{2}:\\d{2} \\(IST\\) \\d{1,2} \\w{3} \\d{4}\"),\n",
    "        ]\n",
    "\n",
    "        for fmt, rgx in date_patterns:\n",
    "            for match in re.finditer(rgx, self.html, re.IGNORECASE):\n",
    "                substring = match.group(0)\n",
    "                try:\n",
    "                    parsed_date = datetime.strptime(substring, fmt)\n",
    "                    if parsed_date.year < 2000:     parsed_date = parsed_date.replace(year=datetime.now().year)\n",
    "                    return parsed_date.isoformat()\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7S8UD19IYX4G"
   },
   "outputs": [],
   "source": [
    "def scrape_article(obj):\n",
    "    try:\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "        article = CustomArticle(obj['link'], config=get_config())\n",
    "        article.build()\n",
    "        return {\n",
    "            \"url\": obj['link'],\n",
    "            \"source_url\": article.source_url,\n",
    "            \"title\": article.title,\n",
    "            \"text\": article.title+\"\\n\"+article.text,\n",
    "            \"metadata\": article.meta_data,\n",
    "            \"authors\": article.authors,\n",
    "            \"description\": article.meta_description,\n",
    "            \"date_metadata\": article.datetime,\n",
    "            \"date_published\": no_tz(article.publish_date).isoformat() if article.publish_date else None,\n",
    "            \"date_google\": no_tz(datetime.fromisoformat(obj['time'])).isoformat() if obj['time'] else None,\n",
    "            \"date_target\": no_tz(datetime.fromisoformat(obj['target'])).isoformat() if obj['target'] else None,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"[{obj['target']}] Failed to scrape {obj['link']}: {e}\")\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../news_links/data/search_results_1732512728.458377.csv\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "for filename in sorted(glob.glob('../news_links/data/search_results_*.csv')):\n",
    "    TS = re.search(r'_(\\d+\\.\\d+)\\.', filename).group(1)\n",
    "    if os.path.exists(f'./data/newsdata_{TS}.json'):    continue\n",
    "\n",
    "    print(f\"Processing: {filename}\")\n",
    "    results_df = pd.read_csv(filename, sep='|').fillna('').sample(10)\n",
    "    raw = results_df.apply(scrape_article, axis=1).tolist()\n",
    "    data = [item for item in raw if 'source_url' in item.keys()]\n",
    "    redo = [item for item in raw if 'source_url' not in item.keys()]\n",
    "    with open(f'./data/newsdata_{TS}.json', 'w') as f:\n",
    "        json.dump(data, f, indent=4, sort_keys=True)\n",
    "    pd.DataFrame(redo).to_csv(f'./redo/search_results_{TS}.csv', sep='|', index=False)\n",
    "    time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2jP2eLoGYX4D",
    "c8ejA8gqYX4F",
    "nTjuwikcYX4F"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
